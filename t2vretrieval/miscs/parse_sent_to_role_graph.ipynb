{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/data2/csz/MSRVTT'\n",
    "# root_dir = '/data2/csz/TGIF'\n",
    "root_dir = '/data2/csz/VATEX'\n",
    "\n",
    "anno_dir = os.path.join(root_dir, 'annotation', 'RET')\n",
    "os.makedirs(anno_dir, exist_ok=True)\n",
    "\n",
    "# input files\n",
    "sent2srl_file = os.path.join(anno_dir, 'sent2srl.json')\n",
    "\n",
    "# output files\n",
    "sent2rg_file = os.path.join(anno_dir, 'sent2rolegraph.json')\n",
    "sent2rga_file = os.path.join(anno_dir, 'sent2rolegraph.augment.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Sentence to Role Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2srl = json.load(open(sent2srl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_role_graph_data(srl_data):\n",
    "  words = srl_data['words']\n",
    "  verb_items = srl_data['verbs']\n",
    "    \n",
    "  graph_nodes = {}\n",
    "  graph_edges = []\n",
    "    \n",
    "  root_name = 'ROOT'\n",
    "  graph_nodes[root_name] = {'words': words, 'spans': list(range(0, len(words))), 'role': 'ROOT'}\n",
    "    \n",
    "  # parse all verb_items\n",
    "  phrase_items = []\n",
    "  for i, verb_item in enumerate(verb_items):\n",
    "    tags = verb_item['tags']\n",
    "    tag2idxs = {}\n",
    "    tagname_counter = {} # multiple args of the same role\n",
    "    for t, tag in enumerate(tags):\n",
    "      if tag == 'O':\n",
    "        continue\n",
    "      if t > 0 and tag[0] != 'B':\n",
    "        # deal with some parsing mistakes, e.g. (B-ARG0, O-ARG1)\n",
    "        # change it into (B-ARG0, B-ARG1)\n",
    "        if tag[2:] != tags[t-1][2:]:\n",
    "          tag = 'B' + tag[1:]\n",
    "      tagname = tag[2:]\n",
    "      if tag[0] == 'B':\n",
    "        if tagname not in tagname_counter:\n",
    "          tagname_counter[tagname] = 1\n",
    "        else:\n",
    "          tagname_counter[tagname] += 1\n",
    "      new_tagname = '%s:%d'%(tagname, tagname_counter[tagname])\n",
    "      tag2idxs.setdefault(new_tagname, [])\n",
    "      tag2idxs[new_tagname].append(t)\n",
    "    if len(tagname_counter) > 1 and 'V' in tagname_counter and tagname_counter['V'] == 1:\n",
    "      phrase_items.append(tag2idxs)\n",
    "\n",
    "  node_idx = 1\n",
    "  spanrole2nodename = {}\n",
    "  for i, phrase_item in enumerate(phrase_items):\n",
    "    # add verb node to graph\n",
    "    tagname = 'V:1'\n",
    "    role = 'V'\n",
    "    spans = phrase_item[tagname]\n",
    "    spanrole = '-'.join([str(x) for x in spans] + [role])\n",
    "    if spanrole in spanrole2nodename:\n",
    "      continue\n",
    "    node_name = str(node_idx)\n",
    "    tag_words = [words[idx] for idx in spans]\n",
    "    graph_nodes[node_name] = {\n",
    "      'role': role, 'spans': spans, 'words': tag_words,\n",
    "    }\n",
    "    spanrole2nodename[spanrole] = node_name\n",
    "    verb_node_name = node_name\n",
    "    node_idx += 1\n",
    "    \n",
    "    # add arg nodes and edges of the verb node\n",
    "    for tagname, spans in phrase_item.items():\n",
    "      role = tagname.split(':')[0]\n",
    "      if role != 'V':\n",
    "        spanrole = '-'.join([str(x) for x in spans] + [role])\n",
    "        if spanrole in spanrole2nodename:\n",
    "          node_name = str(spanrole2nodename[spanrole])\n",
    "        else:\n",
    "          # add new node or duplicate a node with a different role\n",
    "          node_name = str(node_idx)\n",
    "          tag_words = [words[idx] for idx in spans]\n",
    "          graph_nodes[node_name] = {\n",
    "            'role': role, 'spans': spans, 'words': tag_words,\n",
    "          }\n",
    "          spanrole2nodename[spanrole] = node_name\n",
    "          node_idx += 1\n",
    "        # add edge\n",
    "        graph_edges.append((verb_node_name, node_name, role))\n",
    "            \n",
    "  return graph_nodes, graph_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2graph = {}\n",
    "for sent, srl in sent2srl.items():\n",
    "    try:\n",
    "        graph_nodes, graph_edges = create_role_graph_data(srl)\n",
    "        sent2graph[sent] = (graph_nodes, graph_edges)\n",
    "    except:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sent2graph, open(sent2rg_file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sents without non-root nodes: 3504\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for sent, graph in sent2graph.items():\n",
    "  if len(graph[0]) == 1:\n",
    "    n += 1\n",
    "#     print(sent)\n",
    "print('#sents without non-root nodes:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Graph if no SRL is detected (no verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124654\n"
     ]
    }
   ],
   "source": [
    "for sent, graph in sent2graph.items():\n",
    "  nodes, edges = graph\n",
    "  node_idx = len(nodes)\n",
    "                        \n",
    "  # add noun and verb word node if no noun and no noun phrases\n",
    "  if len(nodes) == 1:\n",
    "    doc = nlp(sent)\n",
    "    assert len(doc) == len(nodes['ROOT']['words']), sent\n",
    "    \n",
    "    # add noun nodes\n",
    "    for w in doc.noun_chunks:\n",
    "      node_name = str(node_idx)\n",
    "      nodes[node_name] = {\n",
    "        'role': 'NOUN', 'spans': np.arange(w.start, w.end).tolist()\n",
    "      }\n",
    "      nodes[node_name]['words'] = [doc[j].text for j in nodes[node_name]['spans']]\n",
    "      node_idx += 1\n",
    "    if len(nodes) == 1:\n",
    "      for w in doc:\n",
    "        node_name = str(node_idx)\n",
    "        if w.tag_.startswith('NN'):\n",
    "          nodes[node_name] = {\n",
    "            'role': 'NOUN', 'spans': [w.i], 'words': [w.text],\n",
    "          }\n",
    "          node_idx += 1\n",
    "    \n",
    "    # add verb nodes\n",
    "    for w in doc:\n",
    "      node_name = str(node_idx)\n",
    "      if w.tag_.startswith('VB'):\n",
    "        nodes[node_name] = {\n",
    "          'role': 'V', 'spans': [w.i], 'words': [w.text],\n",
    "        }\n",
    "        node_idx += 1\n",
    "    \n",
    "  sent2graph[sent] = (nodes, edges)\n",
    "  \n",
    "print(len(sent2graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sent2graph, open(sent2rga_file, 'w'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "role_types = collections.Counter()\n",
    "for sent, graph in sent2graph.items():\n",
    "  nodes = graph[0]\n",
    "  for k, v in nodes.items():\n",
    "    role_types[v['role']] += 1\n",
    "print(len(role_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V', 209170),\n",
       " ('ARG1', 137677),\n",
       " ('ARG0', 131884),\n",
       " ('ROOT', 124654),\n",
       " ('ARG2', 38411),\n",
       " ('ARGM-DIR', 30282),\n",
       " ('ARGM-LOC', 23348),\n",
       " ('ARGM-TMP', 18048),\n",
       " ('ARGM-MNR', 16621),\n",
       " ('ARGM-ADV', 4797),\n",
       " ('NOUN', 3551),\n",
       " ('ARG4', 1856),\n",
       " ('ARGM-PRP', 1817),\n",
       " ('ARG3', 1725),\n",
       " ('R-ARG0', 1598),\n",
       " ('ARGM-PRD', 1455),\n",
       " ('R-ARG1', 1037),\n",
       " ('ARGM-GOL', 771),\n",
       " ('ARGM-COM', 689),\n",
       " ('C-ARG1', 389),\n",
       " ('ARGM-NEG', 259),\n",
       " ('ARGM-CAU', 237),\n",
       " ('ARGM-EXT', 204),\n",
       " ('ARGM-MOD', 112),\n",
       " ('ARGM-DIS', 87),\n",
       " ('R-ARGM-LOC', 47),\n",
       " ('ARGM-LVB', 45),\n",
       " ('ARGM-ADJ', 43),\n",
       " ('C-ARG0', 43),\n",
       " ('ARGM-REC', 36),\n",
       " ('ARGM-PNC', 29),\n",
       " ('R-ARG2', 25),\n",
       " ('C-ARGM-ADV', 3),\n",
       " ('ARG5', 2),\n",
       " ('C-ARG2', 2),\n",
       " ('C-ARG4', 2),\n",
       " ('R-ARGM-MOD', 2),\n",
       " ('R-ARGM-TMP', 2),\n",
       " ('R-ARGM-MNR', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_types.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 3.346358720939561 14 5.0 6.0\n"
     ]
    }
   ],
   "source": [
    "# noun per sent\n",
    "nouns_per_sent = []\n",
    "for sent, graph in sent2graph.items():\n",
    "  n_nouns = 0\n",
    "  for node_id, node in graph[0].items():\n",
    "    if node['role'] != 'ROOT' and node['role'] != 'V':\n",
    "      n_nouns += 1\n",
    "  if n_nouns == 0:\n",
    "    print(sent)\n",
    "  nouns_per_sent.append(n_nouns)\n",
    "nouns_per_sent = np.array(nouns_per_sent)\n",
    "print(np.sum(nouns_per_sent == 0), np.min(nouns_per_sent), np.mean(nouns_per_sent), np.max(nouns_per_sent),\n",
    "     np.percentile(nouns_per_sent, 90), np.percentile(nouns_per_sent, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 0 1.6780047170568133 6 3.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# verb per sent\n",
    "verbs_per_sent = []\n",
    "for sent, graph in sent2graph.items():\n",
    "  n_verbs = 0\n",
    "  for node_id, node in graph[0].items():\n",
    "    if node['role'] == 'V':\n",
    "      n_verbs += 1\n",
    "  verbs_per_sent.append(n_verbs)\n",
    "verbs_per_sent = np.array(verbs_per_sent)\n",
    "print(np.sum(verbs_per_sent == 0), np.min(verbs_per_sent), np.mean(verbs_per_sent), np.max(verbs_per_sent),\n",
    "     np.percentile(verbs_per_sent, 90), np.percentile(verbs_per_sent, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ROOT': {'words': ['a',\n",
       "    'egg',\n",
       "    'has',\n",
       "    'been',\n",
       "    'broken',\n",
       "    'and',\n",
       "    'dropped',\n",
       "    'into',\n",
       "    'the',\n",
       "    'cup',\n",
       "    'and',\n",
       "    'a',\n",
       "    'water',\n",
       "    'is',\n",
       "    'boiling',\n",
       "    'in',\n",
       "    'the',\n",
       "    'sauce',\n",
       "    'pan'],\n",
       "   'spans': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "   'role': 'ROOT'},\n",
       "  '1': {'role': 'V', 'spans': [4], 'words': ['broken']},\n",
       "  '2': {'role': 'ARG1', 'spans': [0, 1], 'words': ['a', 'egg']},\n",
       "  '3': {'role': 'V', 'spans': [6], 'words': ['dropped']},\n",
       "  '4': {'role': 'ARG4', 'spans': [7, 8, 9], 'words': ['into', 'the', 'cup']},\n",
       "  '5': {'role': 'V', 'spans': [14], 'words': ['boiling']},\n",
       "  '6': {'role': 'ARG1', 'spans': [11, 12], 'words': ['a', 'water']},\n",
       "  '7': {'role': 'ARGM-LOC',\n",
       "   'spans': [15, 16, 17, 18],\n",
       "   'words': ['in', 'the', 'sauce', 'pan']}},\n",
       " [('1', '2', 'ARG1'),\n",
       "  ('3', '2', 'ARG1'),\n",
       "  ('3', '4', 'ARG4'),\n",
       "  ('5', '6', 'ARG1'),\n",
       "  ('5', '7', 'ARGM-LOC')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2graph['a egg has been broken and dropped into the cup and a water is boiling in the sauce pan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
